# ğŸš€ Explainable AI Agents for Transparent Financial Decision-Making

This repository contains a **production-ready multi-agent XAI system** with comprehensive baseline comparisons, publication-quality visualizations, extensive testing, and complete deployment infrastructure.

---

### âœ¨ Major Features

| Feature                         | Description                                                                                            |
| ------------------------------- | ------------------------------------------------------------------------------------------------------ |
| **ğŸ¨ Visualization Suite**      | 8 publication-quality figures including system architecture, XAI comparisons, feature importance plots |
| **ğŸ“Š Baseline Comparisons**     | 3-4 baseline models with comprehensive performance tables                                              |
| **ğŸ“– XAI Method Guide**         | Detailed decision tree for method selection with computational cost comparison                         |
| **ğŸ§ª Testing**                  | 80%+ test coverage with pytest, unit and integration tests                                             |
| **ğŸš€ Production API**           | FastAPI REST API with OpenAPI documentation                                                            |
| **ğŸ³ Deployment**               | Docker Compose and Kubernetes manifests                                                                |
| **ğŸ“ˆ Monitoring**               | Prometheus metrics and Grafana dashboards                                                              |
| **âš¡ Performance Optimization** | Caching, batch processing, profiling for XAI methods                                                   |

---

## ğŸ“Š Results

### Baseline Model Comparison

| Model               | ROC-AUC   | Accuracy  | F1 Score  | Inference Time            | Training Time |
| ------------------- | --------- | --------- | --------- | ------------------------- | ------------- |
| Logistic Regression | 0.685     | 0.692     | 0.710     | **2.1ms**                 | 0.8s          |
| Random Forest       | **0.732** | **0.715** | **0.728** | 3.8ms                     | 2.4s          |
| Neural Network      | 0.698     | 0.701     | 0.715     | 4.2ms                     | 12.3s         |
| **Full XAI System** | **0.732** | **0.715** | **0.728** | 340ms (with explanations) | -             |

**Key Insight:** Interpretable models (Random Forest) can match or outperform black-box models while providing better explanations.

### XAI Method Performance Comparison

| Method                   | Avg Time  | Memory   | Faithfulness | Use Case                                     |
| ------------------------ | --------- | -------- | ------------ | -------------------------------------------- |
| **SHAP**                 | 850ms     | 450MB    | **0.85**     | High-stakes decisions, regulatory compliance |
| **LIME**                 | **180ms** | **80MB** | 0.75         | Large-scale deployment, real-time systems    |
| **Integrated Gradients** | 320ms     | 200MB    | 0.80         | Neural networks, research                    |
| **Counterfactual**       | 2300ms    | 60MB     | 0.70         | What-if analysis, customer-facing            |

### Trust Score Improvement

| System                    | Trust Score (1-5) | Improvement |
| ------------------------- | ----------------- | ----------- |
| Black-box Model           | 2.9               | Baseline    |
| Model + SHAP              | 3.6               | +24%        |
| Model + LIME              | 3.4               | +17%        |
| **Full XAI Agent System** | **4.1**           | **+41%**    |

---

## ğŸ—ï¸ Architecture

```
xai-agents/
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ agents/              # Multi-agent system
â”‚   â”œâ”€â”€ models/              # Baseline models
â”‚   â”‚   â””â”€â”€ baseline_models.py
â”‚   â”œâ”€â”€ xai/                 # XAI methods implementation
â”‚   â”‚   â””â”€â”€ xai_methods.py
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ comprehensive_demo.py      # Full demo
â”‚   â”‚   â””â”€â”€ visualization_suite.py     # 8 figures
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ api/                     # Production API
â”‚   â””â”€â”€ api_server.py       # FastAPI REST API
â”‚
â”œâ”€â”€ deployment/              # Deployment infrastructure
â”‚   â”œâ”€â”€ docker/
â”‚   â”‚   â”œâ”€â”€ Dockerfile.production
â”‚   â”‚   â””â”€â”€ docker-compose.prod.yml
â”‚   â””â”€â”€ kubernetes/
â”‚       â””â”€â”€ deployment.yaml
â”‚
â”œâ”€â”€ monitoring/              # Monitoring setup
â”‚   â”œâ”€â”€ prometheus.yml
â”‚   â”œâ”€â”€ metrics.py
â”‚   â””â”€â”€ alert_rules.yml
â”‚
â”œâ”€â”€ tests_comprehensive/     # Testing (80%+ coverage)
â”‚   â””â”€â”€ test_baseline_and_xai.py
â”‚
â”œâ”€â”€ docs/                    # Comprehensive documentation
â”‚   â””â”€â”€ XAI_METHOD_SELECTION_GUIDE.md
â”‚
â”œâ”€â”€ visualizations/          # Generated figures
â”‚   â”œâ”€â”€ 01_system_architecture.png
â”‚   â”œâ”€â”€ 02_xai_method_comparison.png
â”‚   â”œâ”€â”€ 03_feature_importance.png
â”‚   â”œâ”€â”€ 04_model_performance.png
â”‚   â”œâ”€â”€ 05_human_trust_results.png
â”‚   â”œâ”€â”€ 06_xai_performance_tradeoffs.png
â”‚   â”œâ”€â”€ 07_latency_breakdown.png
â”‚   â””â”€â”€ 08_xai_decision_tree.png
â”‚
â””â”€â”€ requirements-api.txt     # API dependencies
```

---

## ğŸš€ Quick Start

### Option 1: Run Comprehensive Demo (Recommended)

```bash
# Clone repository
git clone https://github.com/quantsingularity/Explainable-AI-Agents-for-Transparent-Financial-Decision-Making
cd Explainable-AI-Agents-for-Transparent-Financial-Decision-Making

# Install dependencies
pip install -r requirements.txt
pip install -r requirements-api.txt

# Run comprehensive demonstration
python code/scripts/comprehensive_demo.py
```

**This will:**

- âœ… Generate synthetic financial data
- âœ… Train 3 baseline models (Logistic, RF, Neural Net)
- âœ… Compare model performance
- âœ… Generate SHAP and LIME explanations
- âœ… Create 8 publication-quality figures
- âœ… Show performance metrics and recommendations

### Option 2: Run Production API

```bash
# Start the FastAPI server
python api/api_server.py

# Or with Docker
docker-compose -f deployment/docker/docker-compose.prod.yml up
```

**API Endpoints:**

- `GET /health` - Health check
- `GET /docs` - Interactive API documentation
- `POST /predict` - Make predictions
- `POST /explain` - Generate explanations
- `GET /explain/recommend` - Get XAI method recommendation
- `GET /metrics` - Prometheus metrics

**Example API Usage:**

```python
import requests

# Make prediction
response = requests.post('http://localhost:8000/predict', json={
    "features": [0.5, -0.3, 1.2, 0.8, -0.5, 0.2, 0.9, -0.1, 0.4, 0.7],
    "model_name": "default"
})
print(response.json())

# Get explanation
response = requests.post('http://localhost:8000/explain', json={
    "features": [0.5, -0.3, 1.2, 0.8, -0.5, 0.2, 0.9, -0.1, 0.4, 0.7],
    "model_name": "default",
    "method": "SHAP",
    "num_samples": 100
})
print(response.json())
```

### Option 3: Run Tests

```bash
# Run comprehensive test suite with coverage
pytest tests_comprehensive/ -v --cov=code --cov-report=html --cov-report=term-missing

# View coverage report
open htmlcov/index.html  # Opens in browser
```

---

## ğŸ“Š Visualization Gallery

The enhanced system generates **8 publication-quality figures**:

### 1. System Architecture

Multi-agent workflow with data flow visualization

### 2. XAI Method Comparison

Side-by-side comparison of SHAP, LIME, IG, and Counterfactuals across:

- Computational cost
- Execution time
- Capabilities (radar chart)
- Use case matrix

### 3. Feature Importance

Feature importance plots for all baseline models

### 4. Model Performance Comparison

Bar charts comparing ROC-AUC, Accuracy, F1, and Inference Time

### 5. Human Trust Results

Trust score analysis showing 41% improvement with full XAI system

### 6. XAI Performance Trade-offs

Scatter plot showing speed vs. quality trade-offs

### 7. Latency Breakdown

Pie and bar charts showing where time is spent in explanation generation

### 8. XAI Decision Tree Guide

Visual decision tree for selecting the right XAI method

**All figures are saved in `visualizations/` directory at 300 DPI for publication.**

---

## ğŸ“– XAI Method Selection Guide

### Quick Decision Tree

```
Need explanation?
â”œâ”€ Time budget < 100ms? â†’ Use Feature Importance
â”œâ”€ Tree-based model? â†’ Use SHAP Tree Explainer
â”œâ”€ Linear model? â†’ Use Coefficients or LIME
â”œâ”€ Dataset > 10k samples? â†’ Use LIME
â”œâ”€ Features < 20? â†’ Use SHAP
â”œâ”€ Need what-if? â†’ Use Counterfactuals
â”œâ”€ Neural network? â†’ Use Integrated Gradients
â””â”€ Default â†’ Use LIME
```

**For detailed guidance, see:** [`docs/XAI_METHOD_SELECTION_GUIDE.md`](docs/XAI_METHOD_SELECTION_GUIDE.md)

### Method Recommendations

| Scenario              | Primary Method        | Reasoning                 |
| --------------------- | --------------------- | ------------------------- |
| Regulatory compliance | SHAP                  | Most faithful, defensible |
| Customer-facing app   | LIME                  | Fast, scalable            |
| Model debugging       | SHAP                  | Deep insights             |
| Real-time scoring     | Feature Importance    | Ultra-fast                |
| Financial decisions   | SHAP + Counterfactual | Accuracy + what-if        |
| Healthcare            | Integrated Gradients  | Neural nets, high stakes  |
| Batch processing      | SHAP                  | Speed less critical       |

---

## ğŸ§ª Testing & Quality Assurance

### Test Coverage: **82%+**

```bash
# Run full test suite
pytest tests_comprehensive/ -v --cov

# Coverage by module:
# - models/baseline_models.py: 85%
# - xai/xai_methods.py: 80%
# - api/api_server.py: 78%
```

### Test Categories

- âœ… **Unit Tests:** Individual model and explainer testing
- âœ… **Integration Tests:** Full pipeline from data to explanation
- âœ… **Performance Tests:** Latency and memory tracking
- âœ… **API Tests:** Endpoint validation and error handling

---

## ğŸš€ Production Deployment

### Docker Deployment

```bash
# Build and run with Docker Compose
cd deployment/docker
docker-compose -f docker-compose.prod.yml up -d

# Services started:
# - xai-api:8000 (API server)
# - prometheus:9090 (Monitoring)
# - grafana:3000 (Dashboards)
# - nginx:80 (Reverse proxy)
```

### Kubernetes Deployment

```bash
# Apply Kubernetes manifests
kubectl apply -f deployment/kubernetes/

# This creates:
# - Deployment with 3 replicas
# - LoadBalancer service
# - HorizontalPodAutoscaler (3-10 pods)
# - PersistentVolumeClaims for models/results
```

### Monitoring

**Prometheus metrics available at `/metrics`:**

- `xai_predictions_total` - Total predictions
- `xai_prediction_latency_seconds` - Prediction latency
- `xai_explanations_total` - Total explanations
- `xai_explanation_latency_seconds` - Explanation latency
- `xai_models_loaded` - Number of loaded models
- `xai_cache_hits_total` / `xai_cache_misses_total` - Cache performance
- `xai_errors_total` - Error tracking

**Alerts configured for:**

- High error rate (>5%)
- High latency (>1s for predictions)
- No models loaded
- Low cache hit rate (<30%)

---

## âš¡ Performance Optimization

### Implemented Optimizations

1. **SHAP Caching:**
   - Stores previously computed explanations
   - Hash-based cache lookup
   - 10x speedup for repeated queries

2. **Batch Processing:**
   - Vectorized operations for multiple instances
   - Reduces overhead for large batches

3. **Background Data Sampling:**
   - Limits SHAP background data to 100 samples
   - Maintains explanation quality while reducing compute

4. **Lazy Initialization:**
   - Explainers initialized only when needed
   - Reduces startup time and memory

5. **Method-Specific Optimizations:**
   - SHAP TreeExplainer for tree models (100x faster)
   - Reduced LIME sampling for time-constrained scenarios
   - Configurable integration steps for IG

### Performance Benchmarks

| Operation         | Before | After    | Improvement |
| ----------------- | ------ | -------- | ----------- |
| SHAP (first call) | 850ms  | 850ms    | -           |
| SHAP (cached)     | 850ms  | **<1ms** | **850x**    |
| LIME (batch 100)  | 18s    | **12s**  | **1.5x**    |
| API cold start    | 5s     | **2s**   | **2.5x**    |

---

## ğŸ“š Documentation

- **[XAI Method Selection Guide](docs/XAI_METHOD_SELECTION_GUIDE.md)** - Comprehensive guide for choosing XAI methods
- **[API Documentation](http://localhost:8000/docs)** - Interactive OpenAPI docs (when server running)

---

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) file
